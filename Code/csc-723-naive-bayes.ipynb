{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>CSC 723 Final Project</center>\nProject Code 1: Naive Bayes\n\n&emsp; Version 1.0<br> \n&emsp; March 2023\n\n&emsp; CSC 723<br>\n&emsp; Machine Learning for Cyber Security<br>\n&emsp; Dakota State University\n\nRobert Chavez<br>\nKiera Conway","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"--------","metadata":{}},{"cell_type":"markdown","source":"## Import Data\n### Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np   # array mathematical operations library\nimport pandas as pd  # data analysis library3","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:55.878895Z","iopub.execute_input":"2023-03-21T03:56:55.879320Z","iopub.status.idle":"2023-03-21T03:56:55.885464Z","shell.execute_reply.started":"2023-03-21T03:56:55.879275Z","shell.execute_reply":"2023-03-21T03:56:55.884223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####  <a id=install>Installing chardet</a>","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n    <b>[1]:</b>\n\nUnless previously installed, the `import chardet` cell will produce a `ModuleNotFoundError` error. If that error occurs, uncomment and run the following cell to install the module - if it is already installed, skip ahead to [Importing chardet](#import).\n</div>","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"# !pip install chardet","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-03-21T03:56:55.898231Z","iopub.execute_input":"2023-03-21T03:56:55.898638Z","iopub.status.idle":"2023-03-21T03:56:55.903216Z","shell.execute_reply.started":"2023-03-21T03:56:55.898602Z","shell.execute_reply":"2023-03-21T03:56:55.901907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <a id=import>Importing chardet</a>","metadata":{}},{"cell_type":"code","source":"import chardet       # universal character encoding detector","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:55.914081Z","iopub.execute_input":"2023-03-21T03:56:55.915014Z","iopub.status.idle":"2023-03-21T03:56:55.920564Z","shell.execute_reply.started":"2023-03-21T03:56:55.914966Z","shell.execute_reply":"2023-03-21T03:56:55.919165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n    <b>[2]:</b>\n\nPossible Warnings and Errors:\n    \n* `ModuleNotFoundError: No module named 'chardet'`\n    * Fix: Go to [Installing chardet](#install), uncomment cell, and run it. \n    * Note: It will be using sudo permissions to install a library. For information about the library, please visit [the official site](https://pypi.org/project/chardet/).\n\n\n* `ERROR: Could not find a version that satisfies the requirement chardet (from versions: none)`\n    * Fix: Go to Notebook Settings (right-hand side), navigate to Notebook Options, and ensure internet access is enabled.\n\n\n* `ERROR: No matching distribution found for chardet`\n    * Fix: Go to Notebook Settings (right-hand side), navigate to Notebook Options, and ensure internet access is enabled.\n\n\n* `WARNING: There was an error checking the latest version of pip.`\n    * Fix: Go to Notebook Settings (right-hand side), navigate to Notebook Options, and ensure internet access is enabled.\n</div>","metadata":{}},{"cell_type":"markdown","source":"### Data Set","metadata":{}},{"cell_type":"code","source":"# Set File Path\nfile_path = '/kaggle/input/spam-or-ham/SMSCollection.csv'\n\n# Obtain Data from File Path\nsms_data = pd.read_csv(file_path)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:55.928338Z","iopub.execute_input":"2023-03-21T03:56:55.928852Z","iopub.status.idle":"2023-03-21T03:56:55.952982Z","shell.execute_reply.started":"2023-03-21T03:56:55.928807Z","shell.execute_reply":"2023-03-21T03:56:55.951678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Review Dataset\n### Dataset Information","metadata":{}},{"cell_type":"code","source":"# General Information\nsms_data.info()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:55.954365Z","iopub.execute_input":"2023-03-21T03:56:55.954764Z","iopub.status.idle":"2023-03-21T03:56:55.973514Z","shell.execute_reply.started":"2023-03-21T03:56:55.954695Z","shell.execute_reply":"2023-03-21T03:56:55.971886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for null values\nsms_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:55.976222Z","iopub.execute_input":"2023-03-21T03:56:55.977496Z","iopub.status.idle":"2023-03-21T03:56:55.989530Z","shell.execute_reply.started":"2023-03-21T03:56:55.977449Z","shell.execute_reply":"2023-03-21T03:56:55.987541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View first and last 5 Observations\nsms_data","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:55.991531Z","iopub.execute_input":"2023-03-21T03:56:55.991893Z","iopub.status.idle":"2023-03-21T03:56:56.005386Z","shell.execute_reply.started":"2023-03-21T03:56:55.991864Z","shell.execute_reply":"2023-03-21T03:56:56.004295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sms_data.Class[42])      # view variable 2 (message) of 72nd message\nprint(sms_data.sms[42])      # view variable 1 (spam/ham) of 72nd message","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.008479Z","iopub.execute_input":"2023-03-21T03:56:56.008878Z","iopub.status.idle":"2023-03-21T03:56:56.014299Z","shell.execute_reply.started":"2023-03-21T03:56:56.008843Z","shell.execute_reply":"2023-03-21T03:56:56.013481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Statistical Information\nsms_data.describe()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.015407Z","iopub.execute_input":"2023-03-21T03:56:56.015666Z","iopub.status.idle":"2023-03-21T03:56:56.041026Z","shell.execute_reply.started":"2023-03-21T03:56:56.015638Z","shell.execute_reply":"2023-03-21T03:56:56.039386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analyze Information\n\n#### .describe() Key\n\n| Title  | Definition                                 | \n| ------ | --------                                   |\n| Count  | Count/Occurences of each feature           | \n| Unique | The number of possible unique observations |\n| Top    | The most frequent value                    | \n| Freq   | The frequency of the top value             | \n\n#### Data Analysis\n\nThe features of this dataset are 'Class' and 'sms', where 'Class' indicates whether the message is `spam` or a valid sms message, `ham` and 'sms' contains the corresponding message.\n\nThe count values above shows us there are 5572 non-null data enteries in each feature. As each feature contains the same count value, we can conclude there are no missing data points that we need to trim. \n\nThe unique value of 2 under the Class feature verifies all messages are either `spam` or `ham`, and contain no erroneous values. Since the sms feature contains a unique value of 5169, which is less than 5572, we can assume that some messages are identical.\n\nThe top and freq values under Class show us that most messages are categorized as `ham`, with 4825 occurences. We can therefore determine there are 747 remaining messages categorized as `spam`. The top and freq values under sms confirm the previous hypothesis that some messages are identical; we can see that the most frequent message, occuring 30 times, contains the text \"Sorry, I'll call later\"\n\nUsing this information, we can identify the format of our data, determine its completeness, and verify the values contained are expected.","metadata":{}},{"cell_type":"markdown","source":"## Modify Data\n### Create Column: Numerical Representation for Spam/Ham","metadata":{}},{"cell_type":"code","source":"# View first 5 Observations\nprint(\"Before Modification:\\n\") \nsms_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.042801Z","iopub.execute_input":"2023-03-21T03:56:56.043534Z","iopub.status.idle":"2023-03-21T03:56:56.052543Z","shell.execute_reply.started":"2023-03-21T03:56:56.043504Z","shell.execute_reply":"2023-03-21T03:56:56.051761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create New Column\nsms_data['Class_num'] = sms_data.Class.map({'ham':0, 'spam':1})   # Ham becomes 0, Spam becomes 1\n\n# View first 5 Observations\nprint(\"After Modification:\\n\") \nsms_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.053980Z","iopub.execute_input":"2023-03-21T03:56:56.054474Z","iopub.status.idle":"2023-03-21T03:56:56.072546Z","shell.execute_reply.started":"2023-03-21T03:56:56.054438Z","shell.execute_reply":"2023-03-21T03:56:56.071471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# Create Mapping Dictionary\nscale_Class = {\"spam\":1, \"ham\": 0,}\n\n# Execute In-Place Mapping\ndata['Class'].replace(scale_Class, inplace=True)\n\n# View New Data\ndata\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.074581Z","iopub.execute_input":"2023-03-21T03:56:56.076247Z","iopub.status.idle":"2023-03-21T03:56:56.084153Z","shell.execute_reply.started":"2023-03-21T03:56:56.076126Z","shell.execute_reply":"2023-03-21T03:56:56.082799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create Column: Message Lengths","metadata":{}},{"cell_type":"code","source":"# View first 5 Observations\nprint(\"Before Modification:\\n\") \nsms_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.116884Z","iopub.execute_input":"2023-03-21T03:56:56.117281Z","iopub.status.idle":"2023-03-21T03:56:56.132987Z","shell.execute_reply.started":"2023-03-21T03:56:56.117247Z","shell.execute_reply":"2023-03-21T03:56:56.130406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create New Column\nsms_data['sms_len'] = sms_data.sms.apply(len)   #apply length counter to each tweet \n\n# View first 5 Observations\nprint(\"After Modification:\\n\") \nsms_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.171404Z","iopub.execute_input":"2023-03-21T03:56:56.171881Z","iopub.status.idle":"2023-03-21T03:56:56.188170Z","shell.execute_reply.started":"2023-03-21T03:56:56.171844Z","shell.execute_reply":"2023-03-21T03:56:56.187420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Graph Data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns              #statistical data visualization\n\nsns.set_style('whitegrid')          #set visual style\nplt.style.use('fivethirtyeight')   #set plot visual style\nplt.figure(figsize=(12,8))         #set plot size\n\n# Plot Ham/ Spam Message Length as Histogram\nsms_data[sms_data.Class=='ham'].sms_len.plot(bins=35, kind='hist', color='blue', label='Ham Messages', alpha=0.5)\nsms_data[sms_data.Class=='spam'].sms_len.plot(kind='hist', color='red', label='Spam Messages', alpha=0.5)\n\nplt.legend()\nplt.xlabel(\"Message Length\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.189592Z","iopub.execute_input":"2023-03-21T03:56:56.190043Z","iopub.status.idle":"2023-03-21T03:56:56.571864Z","shell.execute_reply.started":"2023-03-21T03:56:56.190011Z","shell.execute_reply":"2023-03-21T03:56:56.570032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyze Data\n### Complete Data Set","metadata":{}},{"cell_type":"code","source":"sms_data.describe()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.576524Z","iopub.execute_input":"2023-03-21T03:56:56.576914Z","iopub.status.idle":"2023-03-21T03:56:56.594267Z","shell.execute_reply.started":"2023-03-21T03:56:56.576879Z","shell.execute_reply":"2023-03-21T03:56:56.593086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analysis\n\n\n* Data set includes Ham (0) and Spam (1) combined into Class_num\n* A Class_num mean of 0.134 means that 13.4% of data is spam\n    * Inversely, 86.6% is Ham\n* SMS messages average 80.48 characters\n* The shortest message length is 2 characters\n* The longest message length is 910 characters\n","metadata":{}},{"cell_type":"markdown","source":"### Ham Data Set","metadata":{}},{"cell_type":"code","source":"# Analyze data labeled 'ham'\nsms_data[sms_data.Class=='ham'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.597349Z","iopub.execute_input":"2023-03-21T03:56:56.597686Z","iopub.status.idle":"2023-03-21T03:56:56.619508Z","shell.execute_reply.started":"2023-03-21T03:56:56.597657Z","shell.execute_reply":"2023-03-21T03:56:56.618763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analysis\n\n\n* This data set includes Ham (0) only\n* There are 4,825 ham messages\n* Remember, ham is 0, so all other stats in Class_num will == 0\n* Ham messages average 71.48 characters\n* The shortest ham message length is 2 characters\n* The longest ham message length is 910 characters","metadata":{}},{"cell_type":"markdown","source":"### Spam Data Set","metadata":{}},{"cell_type":"code","source":"# Analyze data labeled 'spam'\nsms_data[sms_data.Class=='spam'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.621625Z","iopub.execute_input":"2023-03-21T03:56:56.622165Z","iopub.status.idle":"2023-03-21T03:56:56.641683Z","shell.execute_reply.started":"2023-03-21T03:56:56.622130Z","shell.execute_reply":"2023-03-21T03:56:56.640235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analysis\n\n\n* This data set includes Spam (1) only\n* There are 747 spam messages\n* Remember, spam is 1, so all other stats in Class_num will == 1\n    * except standard deviation, as there is no deviation between 1 and 1\n* Spam messages average 138.67 characters\n* The shortest spam message length is 13 characters\n* The longest spam message length is 223 characters","metadata":{}},{"cell_type":"markdown","source":"## Prepare Data using Natural Language Processing\n### Create Function to Clean up Messages","metadata":{}},{"cell_type":"code","source":"import string\nfrom nltk.corpus import stopwords\n\n# List of common abbreviations\nabrv = ['rofl', 'stfu', 'icymi', 'tldr', 'ok', 'tmi', 'afaik', 'lmk', 'nvm', 'ftw', 'byob', 'rt', 'bogo', 'jk', 'jw', 'im', 'pm', 'ig', 'tgif', 'bh', 'tbf', 'rn', 'fubar', 'brb', 'iso', 'brt', 'btw', 'ftfy', 'gg', 'bfd', 'irl', 'dae', 'lol', 'smh', 'ngl', 'bts', 'ikr', 'ttyl', 'hmu', 'fwiw', 'imo', 'wyd', 'imho', 'idk', 'idc', 'idgaf', 'nbd', 'tba', 'tbd', 'afk', 'abt', 'iykyk', 'b4', 'bc', 'jic', 'fomo', 'snafu', 'gtg', 'g2g', 'h8', 'lmao', 'iykwim', 'myob', 'pov', 'tlc', 'bd', 'w/e', 'wtf', 'wysiwyg', 'fwif', 'tw', 'eod', 'faq', 'aka', 'asap', 'diy', 'lmgtfy', 'np', 'n/a', 'ooo', 'ia', 'cob', 'fyi', 'nsfw', 'wfh', 'omw', 'wdyt', 'wygam', 'smp', 'dm', 'fb', 'ig', 'li', 'yt', 'ff', 'im', 'pm', 'op', 'qotd', 'ootd', 'rt', 'tbt', 'til', 'ama', 'eli5', 'fbf', 'mfw', 'hmu', 'ily', 'mcm', 'wcw', 'bf', 'gf', 'ae', 'lysm', 'pda', 'ltr', 'dtr', 'xoxo', 'otp', 'loml']\n\ndef Process_Tweet(sms):\n    \n    STOPWORDS = stopwords.words('english')+abrv                           #set stopwords (SW) variable to nltk english SW\n    \n    nopunc = [char for char in sms if char not in string.punctuation]     #remove punctuation\n    \n    nopunc = ''.join(nopunc)                                              #join every item in list using '' as a separator\n    \n    nopunc = ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])    #remove Stopwords\n\n    return nopunc","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.644321Z","iopub.execute_input":"2023-03-21T03:56:56.644801Z","iopub.status.idle":"2023-03-21T03:56:56.658045Z","shell.execute_reply.started":"2023-03-21T03:56:56.644752Z","shell.execute_reply":"2023-03-21T03:56:56.655862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Code Breakdown\n    \n`nopunc = [char for char in sms if char not in string.punctuation]` <br>\n\" for every character in the message, <br>\nif the character is not in the list of punctionation, <br>\nsave that char into the list 'nopunc' \"\n* removes punctuation\n* Essentially, nopunc is the same as sms, just without the punctuation\n\n\n`nopunc = ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])` <br>\n\" for every word in the 'nopunc' list,  <br>\nif the word [changed to lowercase] is not in 'STOPWORDS',  <br>\nsave it into the list 'nopunc'\"\n\n* remove Stopwords\n","metadata":{}},{"cell_type":"markdown","source":"### Create Column: Save Cleaned Messages","metadata":{}},{"cell_type":"code","source":"# View first 5 Observations\nprint(\"Before Modification:\\n\") \nsms_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.660147Z","iopub.execute_input":"2023-03-21T03:56:56.660809Z","iopub.status.idle":"2023-03-21T03:56:56.682539Z","shell.execute_reply.started":"2023-03-21T03:56:56.660763Z","shell.execute_reply":"2023-03-21T03:56:56.681730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create New Column\nsms_data['sms_clean'] = sms_data.sms.apply(Process_Tweet)   #send each message to function 'temp_process'\n\n# View first 5 Observations\nprint(\"After Modification:\\n\") \nsms_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:56.683675Z","iopub.execute_input":"2023-03-21T03:56:56.684576Z","iopub.status.idle":"2023-03-21T03:56:57.705138Z","shell.execute_reply.started":"2023-03-21T03:56:56.684543Z","shell.execute_reply":"2023-03-21T03:56:57.703985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extract Words\n#### Ham Messages","metadata":{}},{"cell_type":"code","source":"ham_words = sms_data[sms_data.Class_num==0].sms_clean.apply(lambda x: [word.lower() for word in x.split()])    #Save messages as lowercase list\n\n'''\nfor each ham message, \nsplit words into a list, \ncovert to lowercase, \nand save to 'ham_words'\n'''\n\nham_words    #remaining words in ham messages","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:57.706183Z","iopub.execute_input":"2023-03-21T03:56:57.707544Z","iopub.status.idle":"2023-03-21T03:56:57.733504Z","shell.execute_reply.started":"2023-03-21T03:56:57.707511Z","shell.execute_reply":"2023-03-21T03:56:57.732659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Spam Messages","metadata":{}},{"cell_type":"code","source":"spam_words = sms_data[sms_data.Class_num==1].sms_clean.apply(lambda x: [word.lower() for word in x.split()])    #Save messages as lowercase list\n\n'''\nfor each ham message, \nsplit words into a list, \ncovert to lowercase, \nand save to 'ham_words'\n'''\n\nspam_words    #remaining words in spam messages","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:57.734785Z","iopub.execute_input":"2023-03-21T03:56:57.735291Z","iopub.status.idle":"2023-03-21T03:56:57.751858Z","shell.execute_reply.started":"2023-03-21T03:56:57.735258Z","shell.execute_reply":"2023-03-21T03:56:57.750675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Frequency Tables\n### Ham Word Frequencies","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nham_word_count = Counter()\n\nfor each_word in ham_words:                #for each word in words\n    ham_word_count.update(each_word)       #count frequency of each_word\n    \nprint(ham_word_count.most_common(50))      #print 50 most common words","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:57.756315Z","iopub.execute_input":"2023-03-21T03:56:57.756660Z","iopub.status.idle":"2023-03-21T03:56:57.781430Z","shell.execute_reply.started":"2023-03-21T03:56:57.756633Z","shell.execute_reply":"2023-03-21T03:56:57.779947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analysis\n<i>This is a good place to check for additional stopwords.<br>\n    For example, 2 of the top 3 most common words here are 'U' and '2' - these would be great additions to the stopword list\n    \n<i>If unsure about adding a specific word to the stopwords list, ask if the word adds any context - if not, it would likely work well as a stopword.<br> Also, you can check the most common occurences of spam (shown below) and see if that word appears there as well. ","metadata":{}},{"cell_type":"markdown","source":"### Spam Word Frequencies","metadata":{}},{"cell_type":"code","source":"spam_word_count = Counter()\n\nfor each_word in spam_words:              #for each word in words\n    spam_word_count.update(each_word)       #count frequency of each_word\n    \nprint(spam_word_count.most_common(50))      #print 50 most common words","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:57.782530Z","iopub.execute_input":"2023-03-21T03:56:57.783267Z","iopub.status.idle":"2023-03-21T03:56:57.795079Z","shell.execute_reply.started":"2023-03-21T03:56:57.783230Z","shell.execute_reply":"2023-03-21T03:56:57.793680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Naive Base Classifier","metadata":{}},{"cell_type":"code","source":"X = sms_data.sms_clean    #define feature set\ny = sms_data.Class_num    #define dependent variable\n\nprint(X.shape)       #print shape (Observations/ Rows, Features/ Columns)\nprint(y.shape)       #print shape (Observations/ Rows, Features/ Columns)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:57.796886Z","iopub.execute_input":"2023-03-21T03:56:57.798164Z","iopub.status.idle":"2023-03-21T03:56:57.805156Z","shell.execute_reply.started":"2023-03-21T03:56:57.798114Z","shell.execute_reply":"2023-03-21T03:56:57.803934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split Training and Testing Data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:57.806770Z","iopub.execute_input":"2023-03-21T03:56:57.807195Z","iopub.status.idle":"2023-03-21T03:56:57.821068Z","shell.execute_reply.started":"2023-03-21T03:56:57.807152Z","shell.execute_reply":"2023-03-21T03:56:57.819200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verify Training/ Testing Data\nprint(X_train.shape, X_test.shape)\nprint(y_train.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:57.822888Z","iopub.execute_input":"2023-03-21T03:56:57.824593Z","iopub.status.idle":"2023-03-21T03:56:57.833955Z","shell.execute_reply.started":"2023-03-21T03:56:57.824533Z","shell.execute_reply":"2023-03-21T03:56:57.832846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Verification Analysis\n\n* X_train: 4179 observations, 1 feature\n* X_test: 1393 observations, 1 feature\n* y_train: 4179 observations, 1 feature\n* y_test: 1393 observations, 1 feature\n\nSince Training and Testing observations match, and features are the expected value (missing means 1), the training and testing data was split correctly.","metadata":{}},{"cell_type":"markdown","source":"### Obtain Count Vectorizer","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer    #Convert a collection of text documents to a matrix of token counts.\n\n# Fit Data\nvect = CountVectorizer()\nvect.fit(X_train)\n\n#Transform Data\nX_train_dtm = vect.transform(X_train)    #transform train data, dtm = data transformation\nX_test_dtm = vect.transform(X_test)      #transform test data, dtm = data transformation\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:57.834963Z","iopub.execute_input":"2023-03-21T03:56:57.836377Z","iopub.status.idle":"2023-03-21T03:56:57.953821Z","shell.execute_reply.started":"2023-03-21T03:56:57.836314Z","shell.execute_reply":"2023-03-21T03:56:57.952395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Error Check","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:44:22.925667Z","iopub.execute_input":"2023-03-21T03:44:22.926090Z","iopub.status.idle":"2023-03-21T03:44:23.075429Z","shell.execute_reply.started":"2023-03-21T03:44:22.926047Z","shell.execute_reply":"2023-03-21T03:44:23.073584Z"}}},{"cell_type":"code","source":"#Verify Vectorizers Completed\nprint(X_train_dtm.toarray())             #print train vectorizer\nprint(\"\\n\\n\")\nprint(X_train_dtm.toarray())             #print test vectorizer","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:57.955626Z","iopub.execute_input":"2023-03-21T03:56:57.956019Z","iopub.status.idle":"2023-03-21T03:56:58.033289Z","shell.execute_reply.started":"2023-03-21T03:56:57.955978Z","shell.execute_reply":"2023-03-21T03:56:58.031844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_dtm","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:58.034563Z","iopub.execute_input":"2023-03-21T03:56:58.034956Z","iopub.status.idle":"2023-03-21T03:56:58.042444Z","shell.execute_reply.started":"2023-03-21T03:56:58.034921Z","shell.execute_reply":"2023-03-21T03:56:58.040696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dtm","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:58.043730Z","iopub.execute_input":"2023-03-21T03:56:58.044450Z","iopub.status.idle":"2023-03-21T03:56:58.055352Z","shell.execute_reply.started":"2023-03-21T03:56:58.044411Z","shell.execute_reply":"2023-03-21T03:56:58.053637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Transformation Analysis\n\n<i>I can verify the data transformation was successful, as both X_train and X_test<br>\nproduce the same output for columns [rows x colunmns]</i>\n    \n* X_test_dtm\n    * 1393 x **8011**\n* X_train_dtm\n    * 4197 x **8011**","metadata":{}},{"cell_type":"markdown","source":"## Create Naive Base Model","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB \n\nnb = MultinomialNB()          #create instance\nnb.fit(X_train_dtm, y_train)  #fit model","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:58.058171Z","iopub.execute_input":"2023-03-21T03:56:58.058545Z","iopub.status.idle":"2023-03-21T03:56:58.072194Z","shell.execute_reply.started":"2023-03-21T03:56:58.058517Z","shell.execute_reply":"2023-03-21T03:56:58.070341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make Predictions","metadata":{}},{"cell_type":"code","source":"y_pred_class = nb.predict(X_test_dtm)     #make prediction for entire testing set\n\ny_pred_class[:15]","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:58.074217Z","iopub.execute_input":"2023-03-21T03:56:58.074554Z","iopub.status.idle":"2023-03-21T03:56:58.086604Z","shell.execute_reply.started":"2023-03-21T03:56:58.074518Z","shell.execute_reply":"2023-03-21T03:56:58.085153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction Analysis [1 of 2]\n\nReminder: 0 is Ham, 1 is Spam\n\nAccording to this prediction, the fifteenth message (at array location 14) should be spam. We can check this by printing the fifteenth message:","metadata":{}},{"cell_type":"code","source":"X_test[14:15]","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:58.087672Z","iopub.execute_input":"2023-03-21T03:56:58.088033Z","iopub.status.idle":"2023-03-21T03:56:58.098094Z","shell.execute_reply.started":"2023-03-21T03:56:58.088004Z","shell.execute_reply":"2023-03-21T03:56:58.096633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction Analysis [2 of 2]\n\nJudging from this short snippet, it appears that the prediction was correct - this message is Spam","metadata":{}},{"cell_type":"markdown","source":"## Check Accuracy","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\n\nmetrics.accuracy_score(y_test, y_pred_class)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:58.099514Z","iopub.execute_input":"2023-03-21T03:56:58.099831Z","iopub.status.idle":"2023-03-21T03:56:58.113110Z","shell.execute_reply.started":"2023-03-21T03:56:58.099804Z","shell.execute_reply":"2023-03-21T03:56:58.110629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics.confusion_matrix(y_test, y_pred_class)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:58.115318Z","iopub.execute_input":"2023-03-21T03:56:58.115836Z","iopub.status.idle":"2023-03-21T03:56:58.130939Z","shell.execute_reply.started":"2023-03-21T03:56:58.115794Z","shell.execute_reply":"2023-03-21T03:56:58.129829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix Analysis\n\n|                 | Predicted Value<br>[0] | Predicted Value<br>[1] |\n| --------------- | ---------------------- | ---------------------- |\n| True Value [0]  | Prediction Correct     | Prediction Incorrect   |\n| True Value [1]  | Prediction Incorrect   | Prediction Correct     |\n\n| P, T | 0           | 1           |\n| ---- | ----------- | ----------- |\n| 0    | <b>0, 0</b> | 1, 0        |\n| 1    | 0, 1        | <b>1, 1</b> |\n\nTherefore, the stats above state the following\n\n| | |\n| ---------------------------------------------------- | -------------------------------------------------- |\n| 1200 Predicted HAM Correctly                         | 7 Predicted SPAM incorrectly,<br> was actually HAM |\n| 14 Predicted HAM incorrectly,<br> was actually SPAM  | 172 Predicted SPAM Correctly                       |\n","metadata":{}},{"cell_type":"markdown","source":"### Verify Specific Predictions","metadata":{}},{"cell_type":"code","source":"X_test[y_pred_class > y_test]   #view all predictions of SPAM (1) where it was actually HAM (0)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:58.132507Z","iopub.execute_input":"2023-03-21T03:56:58.132802Z","iopub.status.idle":"2023-03-21T03:56:58.142330Z","shell.execute_reply.started":"2023-03-21T03:56:58.132774Z","shell.execute_reply":"2023-03-21T03:56:58.140765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test[y_pred_class < y_test]   #view all predictions of HAM (0) where it was actually SPAM (1)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T03:56:58.144149Z","iopub.execute_input":"2023-03-21T03:56:58.144550Z","iopub.status.idle":"2023-03-21T03:56:58.159805Z","shell.execute_reply.started":"2023-03-21T03:56:58.144505Z","shell.execute_reply":"2023-03-21T03:56:58.158253Z"},"trusted":true},"execution_count":null,"outputs":[]}]}